# ğŸ¬ SceneSearch

**Video Semantic Search** - ìì—°ì–´ë¡œ ì˜ìƒ ì† ì¥ë©´ì„ ê²€ìƒ‰í•˜ì„¸ìš”!

ì˜ìƒì—ì„œ ì›í•˜ëŠ” ì¥ë©´ì„ ì°¾ê³  ì‹¶ì„ ë•Œ, ì¼ì¼ì´ íƒ€ì„ë¼ì¸ì„ ë„˜ê¸°ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
"ì¡°ë‹ˆë ì–¼êµ´", "ì—°êµ¬ì‹¤ ì¥ë©´", "í­ë°œ ì”¬"ì²˜ëŸ¼ ìì—°ì–´ë¡œ ê²€ìƒ‰í•˜ë©´ í•´ë‹¹ ì¥ë©´ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì°¾ì•„ì¤ë‹ˆë‹¤.

![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?logo=pytorch&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

---

## âœ¨ Features

- ğŸ¯ **Scene Detection** - ffmpeg ê¸°ë°˜ ì¥ë©´ ì „í™˜ ê°ì§€ë¡œ íš¨ìœ¨ì ì¸ í”„ë ˆì„ ì¶”ì¶œ
- ğŸ§  **CLIP Embeddings** - OpenAI CLIP ëª¨ë¸ë¡œ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì‹œë§¨í‹± ë§¤ì¹­
- ğŸ” **Natural Language Search** - ì˜ì–´ ìì—°ì–´ë¡œ ì›í•˜ëŠ” ì¥ë©´ ê²€ìƒ‰
- âš¡ **GPU Accelerated** - CUDA ì§€ì›ìœ¼ë¡œ ë¹ ë¥¸ ì„ë² ë”© ìƒì„±

---

## ğŸ› ï¸ Installation

### Requirements
- Python 3.10+
- CUDA (optional, for GPU acceleration)
- ffmpeg

### Setup
```bash
# Clone repository
git clone https://github.com/darkdarkcocoa/SceneSearch.git
cd SceneSearch

# Install dependencies
pip install torch torchvision open-clip-torch opencv-python pillow numpy
```

---

## ğŸš€ Usage

### 1. Frame Extraction (ffmpeg scene detection)
```bash
# ì¥ë©´ ì „í™˜ 30% ì´ìƒì¼ ë•Œë§Œ í”„ë ˆì„ ì¶”ì¶œ
ffmpeg -i your_video.mp4 -vf "select='gt(scene,0.3)',showinfo" -vsync vfr output/frames/frame_%04d.jpg 2>&1 | grep "pts_time" > output/frame_log.txt
```

### 2. Create Metadata
```bash
python create_metadata.py
```

### 3. Generate Embeddings
```bash
python generate_embeddings.py
```

### 4. Search!
```bash
python search_test.py
```

ë˜ëŠ” `prototype.py`ë¡œ ì¸í„°ë™í‹°ë¸Œ ê²€ìƒ‰:
```bash
python prototype.py
```

---

## ğŸ“ Project Structure

```
SceneSearch/
â”œâ”€â”€ app.py                 # Gradio ì›¹ UI
â”œâ”€â”€ prototype.py           # ì˜¬ì¸ì› í”„ë¡œí† íƒ€ì… (ì¶”ì¶œ + ì„ë² ë”© + ê²€ìƒ‰)
â”œâ”€â”€ create_metadata.py     # ffmpeg ë¡œê·¸ â†’ metadata.json ë³€í™˜
â”œâ”€â”€ generate_embeddings.py # CLIP ì„ë² ë”© ìƒì„±
â”œâ”€â”€ search_test.py         # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ output/
    â”œâ”€â”€ frames/            # ì¶”ì¶œëœ í”„ë ˆì„ ì´ë¯¸ì§€
    â”œâ”€â”€ metadata.json      # í”„ë ˆì„ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´
    â””â”€â”€ embeddings.npz     # CLIP ì„ë² ë”© ë²¡í„°
```

---

## ğŸ“Š Example Results

**Transcendence (2014)** ì˜í™”ë¡œ í…ŒìŠ¤íŠ¸í•œ ê²°ê³¼:

| Query | Top Result | Timestamp |
|-------|------------|-----------|
| "Johnny Depp face" | ì¡°ë‹ˆë ì •ë©´ ì–¼êµ´ | 01:02:03 |
| "computer screen" | ì»´í“¨í„° ëª¨ë‹ˆí„° ì¥ë©´ | 05:41 |
| "laboratory" | ì—°êµ¬ì‹¤ ì‹¤í—˜ ì¥ë©´ | 17:07 |
| "outdoor garden" | ì•¼ì™¸ ì •ì› | 01:04:50 |
| "explosion" | í­ë°œ/ì—°ê¸° ì¥ë©´ | 10:40 |

### Performance
- **Frame Extraction**: ~1,125 frames from 2hr movie (scene detection)
- **Embedding Speed**: ~80 frames/sec (RTX 4060 Ti)
- **Search Speed**: Instant (cosine similarity)

---

## ğŸ”§ Configuration

### Scene Detection Threshold
`ffmpeg` ëª…ë ¹ì–´ì—ì„œ `scene` ê°’ ì¡°ì •:
- `0.1` - ë¯¼ê° (í”„ë ˆì„ ë§ìŒ)
- `0.3` - ì ë‹¹ (ê¶Œì¥)
- `0.5` - ë‘”ê° (í”„ë ˆì„ ì ìŒ)

### CLIP Model
í˜„ì¬ `ViT-B-32` ì‚¬ìš© ì¤‘. ë” ì •í™•í•œ ê²€ìƒ‰ì„ ì›í•˜ë©´:
```python
# generate_embeddings.pyì—ì„œ ë³€ê²½
model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14', pretrained='openai')
```

---

## ğŸ—ºï¸ Roadmap

- [ ] í•œêµ­ì–´ ê²€ìƒ‰ ì§€ì› (multilingual CLIP)
- [ ] ì›¹ UI ì¶”ê°€
- [ ] ë²¡í„° DB ì—°ë™ (ëŒ€ìš©ëŸ‰ ì˜ìƒ)
- [ ] ì˜¤ë””ì˜¤/ìë§‰ í†µí•© ê²€ìƒ‰
- [ ] ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›

---

## ğŸ“ License

MIT License

---

## ğŸ™ Acknowledgments

- [OpenCLIP](https://github.com/mlfoundations/open_clip) - CLIP implementation
- [FFmpeg](https://ffmpeg.org/) - Video processing

---

Made with â¤ï¸ and â˜•
